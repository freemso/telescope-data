import logging
import re
from urllib.parse import parse_qs, urlparse

import requests
from bs4 import BeautifulSoup
from requests import RequestException

from utils.cookies import Cookies
from utils.db import DB


class WeiboAPI:
    logger = logging.getLogger(__name__)
    cookies_type = '.weibo.cn'

    BASE_URL = 'https://m.weibo.cn/api/container/getIndex'

    cookies_policies = {
        'max_waiting_seconds': 1,
        'max_validation_days': 9999,
        'max_retry_times': 2,
        'max_forbidden_count': 5,
        'type': cookies_type,
        'use_interval_seconds': 0.001,
    }

    @staticmethod
    def weibo_text(raw_text):
        """å¤„ç†å¾®åšæ¥å£textå­—æ®µ"""
        soup = BeautifulSoup(raw_text, "lxml")
        for a in soup.select('a[data-url]'):
            if a.select('img[src*="timeline_card_small_location_default"]'):
                a.insert_before('ğŸ“')
            else:
                real_link = ""
                data_url = a.get("data-url", "")
                href = a.get("href", "")
                if data_url.startswith("/") or data_url.startswith("http"):
                    real_link = data_url
                elif href.startswith("/") or href.startswith("http"):
                    real_link = href

                if real_link:
                    link_params = parse_qs(urlparse(real_link).query)
                    if link_params.get("url"):
                        real_link = link_params["url"][0]
                    elif link_params.get("target"):
                        real_link = link_params["target"][0]
                    elif link_params.get(""):
                        real_link = link_params[""][0]

                    a.string = (" https://m.weibo.cn%s " if real_link[0] == "/" else " %s ") % real_link

        for img in soup.select('img[src*="//h5.sinaimg.cn/m/emoticon/icon"]'):
            img_alt = img.get("alt")
            if img_alt:
                img.insert_before(img_alt)

        # ä½¿ç”¨æ¢è¡Œç¬¦åˆ†è¡Œ
        for br in soup.find_all("br"):
            br.replace_with("\linebreak")
        result_text = soup.text.replace("\n", "").replace("\linebreak", "\n")

        emoji_map = {
            "[åç¬‘]": "ğŸ˜", "[èˆ”å±]": "ğŸ˜", "[æ±¡]": "ğŸ™ˆ", "[å¾®ç¬‘]": "ğŸ˜ƒ", "[å˜»å˜»]": "ğŸ˜", "[å¯çˆ±]": "ğŸ˜Š",
            "[åƒæƒŠ]": "ğŸ˜±", "[å®³ç¾]": "â˜ºï¸", "[æŒ¤çœ¼]": "ğŸ˜œ", "[é—­å˜´]": "ğŸ¤«", "[é„™è§†]": "ğŸ˜’", "[çˆ±ä½ ]": "ğŸ˜˜", "[æ³ª]": "ğŸ˜­",
            "[å·ç¬‘]": "ğŸ˜‰", "[äº²äº²]": "ğŸ˜š", "[ç”Ÿç—…]": "ğŸ˜·", "[æ„Ÿå†’]": "ğŸ˜·", "[å¤ªå¼€å¿ƒ]": "ğŸ˜", "[ç™½çœ¼]": "ğŸ™„", "[å˜˜]": "ğŸ¤«",
            "[è¡°]": "ğŸ˜°", "[å§”å±ˆ]": "ğŸ˜£", "[å]": "ğŸ¤®", "[å“ˆæ¬ ]": "ğŸ˜´", "[æŠ±æŠ±]": "ğŸ¤—", "[æ€’]": "ğŸ˜¡", "[ç–‘é—®]": "â“", "[æ‹œæ‹œ]": "ğŸ‘‹",
            "[æ€è€ƒ]": "ğŸ¤”", "[æ±—]": "ğŸ˜“", "[å›°]": "ğŸ˜´", "[ç¡]": "ğŸ˜´", "[é’±]": "ğŸ¤‘", "[å¤±æœ›]": "ğŸ˜”", "[é…·]": "ğŸ˜", "[è‰²]": "ğŸ˜",
            "[å“¼]": "ğŸ˜¤", "[å·¦å“¼å“¼]": "ğŸ˜¤", "[å³å“¼å“¼]": "ğŸ˜¤", "[é¼“æŒ]": "ğŸ‘", "[æ‚²ä¼¤]": "ğŸ˜­", "[æ™•]": "ğŸ˜µ", "[å‚»çœ¼]": "ğŸ¤ª",
            "[æŠ“ç‹‚]": "ğŸ˜«", "[é»‘çº¿]": "ğŸ˜…", "[é˜´é™©]": "ğŸ˜", "[æ€’éª‚]": "ğŸ˜¡", "[å¿ƒ]": "â¤ï¸", "[ä¼¤å¿ƒ]": "ğŸ’”", "[çŒªå¤´]": "ğŸ·",
            "[ç†ŠçŒ«]": "ğŸ¼", "[å…”å­]": "ğŸ°", "[ok]": "ğŸ‘Œ", "[è€¶]": "âœŒï¸",
            "[good]": "ğŸ‘", "[NO]": "ğŸ–", "[èµ]": "ğŸ‘", "[å¼±]": "ğŸ‘", "[å›§]": "ğŸ˜°", "[æµ®äº‘]": "â˜ï¸", "[doge]": "ğŸŒš",
            "[å–µå–µ]": "ğŸ±", "[å“†å•¦Aæ¢¦åƒæƒŠ]": "ğŸ™€", "[å“†å•¦Aæ¢¦å¾®ç¬‘]": "ğŸ˜º", "[å“†å•¦Aæ¢¦èŠ±å¿ƒ]": "ğŸ˜»", "[äºŒå“ˆ]": "ğŸ¶",
            "[ä¹¦å‘†å­]": "ğŸ¤“", "[å“ˆå“ˆ]": "ğŸ˜†", "[å¤ªé˜³]": "ğŸŒ", "[æœˆäº®]": "ğŸŒ›", "[è·ªäº†]": "ğŸ¤ª", "[è´¹è§£]": "ğŸ¤”", "[æŒ–é¼»]": "ğŸŒ",
            "[å…æ‚²]": "ğŸ¤¦â€â™‚ï¸", "[å›´è§‚]": "ğŸ‘€", "[æ‘Šæ‰‹]": "ğŸ¤·ğŸ»â€â™‚ï¸", "[è¯ç­’]": "ğŸ¤", "[æ‰“è„¸]": "ğŸ¤ª", "[ç¬‘è€Œä¸è¯­]": "ğŸ¤“", "[åƒç“œ]": "ğŸ‰",
            "[æ†§æ†¬]": "ğŸ¤©", "[å¹¶ä¸ç®€å•]": "ğŸ§", "[èœ¡çƒ›]": "ğŸ•¯ï¸", "[æ‹³å¤´]": "âœŠ", "[åŠ æ²¹]": "ğŸ’ª", "[ç¬‘cry]": "ğŸ˜‚", "[é¦‹å˜´]": "ğŸ˜‹",
            "[å¯æ€œ]": "ğŸ˜¿", "[è›‹ç³•]": "ğŸ°", "[é¡¶]": "ğŸ˜†", "[æ¡æ‰‹]": "ğŸ¤"
        }
        for k, v in emoji_map.items():
            result_text = result_text.replace(k, v)
        result_text = re.sub(re.compile(r'\[.{1,5}\]'), ' ', result_text)  # å°†å…¶ä½™å¯èƒ½æ— æ³•è½¬æ¢çš„è¡¨æƒ…åˆ æ‰
        result_text = re.sub(re.compile(r"\s*\.?\s*\u200b*$"), "", result_text)  # å»æ‰æ–‡æœ¬æœ«å°¾çš„ç‚¹
        result_text = re.sub(re.compile(r"å…¨æ–‡$"), "...", result_text)  # å°†å°¾éƒ¨å…¨æ–‡æ›¿æ¢ä¸º...
        return [result_text.strip()]

    @staticmethod
    def parse_raw_blog(raw_blog):
        """æŠŠrawçš„ä¸€æ¡å¾®åšè½¬åŒ–ä¸ºéœ€è¦çš„æ ¼å¼"""
        blog = {
            "created_at": raw_blog.get("created_at", ""),
            "id": raw_blog.get("id", None),
            "text": WeiboAPI.weibo_text(raw_blog.get("text", "")),
            "source": raw_blog.get("source", ""),
            "author": WeiboAPI.parse_user_info(raw_blog.get("user", {}))
        }
        if raw_blog.get("pic_num", 0) > 0 and "pics" in raw_blog:
            pics = []
            raw_pics = raw_blog.get("pics", [])
            for raw_pic in raw_pics:
                pic = {
                    "pid": raw_pic["pid"],
                    "url": raw_pic["url"]
                }
                if "large" in raw_pic:
                    pic["large_url"] = raw_pic["large"]["url"]
                pics.append(pic)
            blog["pic_num"] = raw_blog["pic_num"]
            blog["pics"] = pics
        return blog

    @staticmethod
    def parse_user_info(user_info_raw):
        """æŠŠrawçš„ä¸€ä¸ªç”¨æˆ·ä¿¡æ¯è½¬åŒ–ä¸ºéœ€è¦çš„æ ¼å¼"""
        return {
            "uid": user_info_raw.get("id", None),
            "screen_name": user_info_raw.get("screen_name", ""),
            "profile_image_url": user_info_raw.get("profile_image_url", ""),
            "gender": user_info_raw.get("gender", None)
        }

    @classmethod
    def get_user_info(cls, uid, raw=False):
        """è·å–ç”¨æˆ·åŸºç¡€ä¿¡æ¯"""

        uid = '%d' % float(uid)
        db = DB.get_crawlerdb()
        cookies_id, cookies = Cookies.get_cookies(cls.cookies_policies, cls.cookies_type, db)
        if not cookies:
            return []

        params = {
            'containerid': '100505{}'.format(uid),
            'type': 'uid',
            'value': uid
        }
        r = requests.get(cls.BASE_URL, params=params, cookies=cookies, timeout=3)
        Cookies.update_cookies(cookies_id, cls.cookies_type, r, db)

        raw_result = r.json()

        if raw_result["ok"] is 0:
            raise RequestException(raw_result['msg'])
        else:
            if raw:
                return raw_result
            else:
                user_info_raw = raw_result["data"]["userInfo"]
                user_info = WeiboAPI.parse_user_info(user_info_raw)
                return user_info

    @classmethod
    def get_user_following(cls, uid):
        """Taå…³æ³¨çš„äºº"""

        uid = '%d' % float(uid)
        db = DB.get_crawlerdb()
        cookies_id, cookies = Cookies.get_cookies(cls.cookies_policies, cls.cookies_type, db)
        if not cookies:
            return []

        params = {
            'luicode': '10000011',
            'lfid': '100505{}'.format(uid),
            'containerid': '231051_-_followers_-_{}'.format(uid),
            'featurecode': '20000320',
            'type': 'uid',
            'value': uid
        }
        followed_id_list = []
        for page_id in range(1, 5):
            params['page'] = page_id
            r = requests.get(cls.BASE_URL, params=params, cookies=cookies, timeout=3)
            Cookies.update_cookies(cookies_id, cls.cookies_type, r, db)
            raw_result = r.json()

            if raw_result["ok"] is 0:
                raise RequestException(raw_result['msg'])
            else:
                if raw_result['data'].get('cards'):
                    for card in raw_result['data']['cards']:
                        for u in card['card_group']:
                            if u['card_type'] == 10:
                                followed_id_list.append(u["user"]["id"])
        return followed_id_list

    @classmethod
    def get_user_blogs(cls, uid, raw=False):
        """Taå‘çš„å¾®åš"""

        db = DB.get_crawlerdb()
        cookies_id, cookies = Cookies.get_cookies(cls.cookies_policies, cls.cookies_type, db)
        if not cookies:
            return None

        params = {
            'type': uid,
            'value': uid,
            'containerid': '107603{}'.format(uid),
            'uid': uid
        }

        blogs = []
        for page_id in range(1, 5):
            params['page'] = page_id
            r = requests.get(cls.BASE_URL, params=params, cookies=cookies, timeout=3)
            Cookies.update_cookies(cookies_id, cls.cookies_type, r, db)
            raw_result = r.json()

            if raw_result["ok"] is 0:
                raise RequestException(raw_result['msg'])
            else:
                if raw:
                    blogs.append(raw_result)
                else:
                    for item in raw_result["data"]["cards"]:
                        if item["card_type"] == 9:
                            raw_blog = item["mblog"]
                            blog = WeiboAPI.parse_raw_blog(raw_blog)
                            blogs.append(blog)
        return blogs

    @classmethod
    def get_user_likes(cls, uid, raw=False):
        """Taèµè¿‡çš„å¾®åš"""
        db = DB.get_crawlerdb()
        cookies_id, cookies = Cookies.get_cookies(cls.cookies_policies, cls.cookies_type, db)
        if not cookies:
            return None

        params = {
            'containerid': '230869{}_-_mix'.format(uid)
        }

        blogs = []
        for page_id in range(1, 5):
            params['page'] = page_id
            r = requests.get(cls.BASE_URL, params=params, cookies=cookies, timeout=3)
            Cookies.update_cookies(cookies_id, cls.cookies_type, r, db)
            raw_result = r.json()

            if raw_result["ok"] is 0:
                raise RequestException(raw_result['msg'])
            else:
                if raw:
                    blogs.append(raw_result)
                else:
                    for item in raw_result["data"]["cards"]:
                        if item["card_type"] == 9:
                            raw_blog = item["mblog"]
                            blog = WeiboAPI.parse_raw_blog(raw_blog)
                            blogs.append(blog)
                        if item["card_type"] == 11:
                            for card in item["card_group"]:
                                if card["card_type"] == 9:
                                    raw_blog = card["mblog"]
                                    blog = WeiboAPI.parse_raw_blog(raw_blog)
                                    blogs.append(blog)
        return blogs

    @classmethod
    def get_blog_detail(cls, weibo_id, raw=False):
        """
        è·å¾—ä¸€æ¡å¾®åšè¯¦ç»†ä¿¡æ¯ã€‚
        :param raw: æ˜¯å¦è¿”å›raw data
        :param weibo_id: å¾®åšid
        """
        db = DB.get_crawlerdb()
        cookies_id, cookies = Cookies.get_cookies(cls.cookies_policies, cls.cookies_type, db)
        if not cookies:
            return None

        url = 'https://m.weibo.cn/statuses/show?id={}'.format(weibo_id)
        r = requests.get(url, cookies=cookies, timeout=3)
        Cookies.update_cookies(cookies_id, cls.cookies_type, r, db)
        raw_result = r.json()

        if raw_result["ok"] is 0:
            raise RequestException(raw_result['msg'])
        else:
            if raw:
                return raw_result
            else:
                raw_blog = raw_result["data"]
                blog = WeiboAPI.parse_raw_blog(raw_blog)
                return blog

    @classmethod
    def get_blog_comments(cls, weibo_id, raw=False):
        """
        è·å¾—ä¸€æ¡å¾®åšä¸‹çš„è¯„è®ºã€‚
        åˆ†é¡µæ¥å£ï¼Œä¸€æ¬¡åªæ‹¿20ä¸ªã€‚
        :param weibo_id: å¾®åšçš„id
        :param raw: æ˜¯å¦è¿”å›raw data
        """
        db = DB.get_crawlerdb()
        cookies_id, cookies = Cookies.get_cookies(cls.cookies_policies, cls.cookies_type, db)
        if not cookies:
            return None

        params = {
            'id': weibo_id,
            'mid': weibo_id
        }
        url = 'https://m.weibo.cn/comments/hotflow'

        comments = []
        for _ in range(1, 5):
            r = requests.get(url, params=params, cookies=cookies, timeout=3)
            Cookies.update_cookies(cookies_id, cls.cookies_type, r, db)
            raw_result = r.json()

            if raw_result["ok"] is 0:
                raise RequestException(raw_result['msg'])
            else:
                raw_data = raw_result["data"]
                params['max_id'] = raw_data["max_id"]
                params['max_id_type'] = raw_data['max_id_type']
                if raw:
                    comments += raw_data['data']
                else:
                    for c in raw_data['data']:
                        comments.append(WeiboAPI.parse_raw_blog(c))

        return comments

    @classmethod
    def get_blog_likes(cls, weibo_id, raw=False):
        """è·å¾—ä¸€æ¡å¾®åšä¸‹çš„ç‚¹èµ"""
        db = DB.get_crawlerdb()
        cookies_id, cookies = Cookies.get_cookies(cls.cookies_policies, cls.cookies_type, db)
        if not cookies:
            return None

        params = {
            'id': weibo_id
        }
        url = 'https://m.weibo.cn/api/attitudes/show'

        likes = []
        for page_id in range(1, 5):
            params['page'] = page_id
            r = requests.get(url, params=params, cookies=cookies, timeout=3)
            Cookies.update_cookies(cookies_id, cls.cookies_type, r, db)
            raw_result = r.json()

            if raw_result["ok"] is 0:
                raise RequestException(raw_result['msg'])
            else:
                raw_data = raw_result["data"]
                if raw:
                    likes += raw_data['data']
                else:
                    for l in raw_data['data']:
                        likes.append(WeiboAPI.parse_raw_blog(l))
        return likes

    @classmethod
    def get_blog_reposts(cls, weibo_id, raw=False):
        """è·å¾—ä¸€æ¡å¾®åšçš„è½¬å‘"""
        db = DB.get_crawlerdb()
        cookies_id, cookies = Cookies.get_cookies(cls.cookies_policies, cls.cookies_type, db)
        if not cookies:
            return None

        params = {
            'id': weibo_id
        }
        url = 'https://m.weibo.cn/api/statuses/repostTimeline'

        reposts = []
        for page_id in range(1, 5):
            params['page'] = page_id
            r = requests.get(url, params=params, cookies=cookies, timeout=3)
            Cookies.update_cookies(cookies_id, cls.cookies_type, r, db)
            raw_result = r.json()

            if raw_result["ok"] is 0:
                raise RequestException(raw_result['msg'])
            else:
                raw_data = raw_result["data"]
                if raw:
                    reposts += raw_data['data']
                else:
                    for l in raw_data['data']:
                        reposts.append(WeiboAPI.parse_raw_blog(l))

        return reposts
